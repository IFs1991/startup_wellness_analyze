# パフォーマンスモニタリングガイド

## 概要

このドキュメントでは、スタートアップウェルネス分析プラットフォームのパフォーマンスモニタリングシステムについて説明します。リファクタリング後のシステムパフォーマンスを継続的に監視し、最適化するための方法とツールを提供します。

## モニタリング指標

以下の主要指標を継続的に監視しています：

### 1. API応答時間

- **エンドポイント別平均応答時間**: 各APIエンドポイントの平均応答時間
- **95パーセンタイル応答時間**: ユーザー体験を評価するための95パーセンタイル値
- **最大応答時間**: ワーストケースのパフォーマンス指標

### 2. データベースパフォーマンス

- **クエリ実行時間**: Firestoreクエリの実行時間
- **クエリ頻度**: 頻度の高いクエリの特定
- **データベース接続数**: アクティブな接続数の追跡

### 3. キャッシュ効率

- **キャッシュヒット率**: Redis/インメモリキャッシュのヒット率
- **キャッシュサイズ**: キャッシュのメモリ使用量
- **平均キャッシュ取得時間**: キャッシュからのデータ取得時間

### 4. システムリソース

- **CPU使用率**: サーバーCPU使用率の追跡
- **メモリ使用量**: サーバーメモリ使用量の追跡
- **ディスクI/O**: ディスク読み書き操作の量

### 5. 非同期処理

- **タスク実行時間**: 非同期タスクの実行時間
- **キュー長**: 非同期タスクキューの長さ
- **タスク処理レート**: 単位時間あたりの処理タスク数

## モニタリングツール

### PrometheusとGrafana

主要なモニタリングシステムとして、PrometheusとGrafanaを使用しています：

```python
# Prometheusメトリクスの例
from prometheus_client import Counter, Histogram, Gauge

# API呼び出し回数のカウンター
api_calls_total = Counter(
    'api_calls_total',
    'Total number of API calls',
    ['endpoint', 'method', 'status']
)

# API応答時間のヒストグラム
api_response_time = Histogram(
    'api_response_time_seconds',
    'API response time in seconds',
    ['endpoint', 'method'],
    buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]
)

# アクティブなユーザー数のゲージ
active_users = Gauge(
    'active_users',
    'Number of active users'
)
```

### ロギングとトレーシング

詳細なパフォーマンス分析のために、構造化ロギングとトレーシングを実装しています：

```python
# パフォーマンスログの例
import time
from contextlib import contextmanager
from core.common_logger import get_logger

logger = get_logger(__name__)

@contextmanager
def performance_log(operation_name):
    """パフォーマンスを記録するコンテキストマネージャー"""
    start_time = time.time()
    try:
        yield
    finally:
        elapsed = time.time() - start_time
        logger.info(
            f"Performance: {operation_name}",
            extra={
                "operation": operation_name,
                "duration_ms": elapsed * 1000,
                "timestamp": time.time()
            }
        )

# 使用例
with performance_log("fetch_user_data"):
    user_data = user_repository.get_user(user_id)
```

## 自動アラート

パフォーマンス問題を迅速に検出するために、自動アラートシステムを設定しています：

1. **しきい値アラート**: 特定の指標が定義されたしきい値を超えた場合にトリガー
2. **異常検出アラート**: 機械学習ベースの異常検出によるアラート
3. **トレンドアラート**: 指標が一定期間にわたって悪化している場合にトリガー

アラートは以下のチャネルに送信されます：
- メール通知
- Slack通知
- オンコールシステム（PagerDuty）

## ダッシュボード

主要なパフォーマンス指標を視覚化するために、以下のダッシュボードを提供しています：

1. **APIパフォーマンスダッシュボード**: エンドポイント別のAPI応答時間とエラー率
2. **システムリソースダッシュボード**: CPU、メモリ、ディスク使用量
3. **データベースパフォーマンスダッシュボード**: クエリ実行時間とデータベースリソース
4. **キャッシュ効率ダッシュボード**: キャッシュヒット率とメモリ使用量
5. **ユーザー体験ダッシュボード**: ユーザーごとのAPI応答時間と満足度指標

## 負荷テスト

システムの性能限界を把握し、スケーラビリティの問題を特定するために、定期的な負荷テストを実施しています：

1. **通常負荷テスト**: 平均的なユーザー負荷のシミュレーション
2. **ピーク負荷テスト**: 予想される最大負荷のシミュレーション
3. **ストレステスト**: システムの限界を超える負荷のシミュレーション
4. **耐久テスト**: 長時間にわたる一定負荷のシミュレーション

負荷テストにはLocustフレームワークを使用しています：

```python
# Locustテストの例
from locust import HttpUser, task, between

class WebsiteUser(HttpUser):
    wait_time = between(1, 5)

    @task(3)
    def view_dashboard(self):
        self.client.get("/api/dashboard")

    @task(1)
    def generate_report(self):
        self.client.post("/api/reports/generate", json={
            "user_id": "test_user",
            "report_type": "wellness_summary"
        })
```

## パフォーマンス最適化プロセス

パフォーマンス問題を特定し解決するための標準プロセス：

1. **問題の特定**: モニタリングシステムを使用して問題領域を特定
2. **原因分析**: プロファイリングとロギングを使用して根本原因を分析
3. **解決策の設計**: パフォーマンス問題を解決するための変更を設計
4. **実装とテスト**: 変更を実装し、負荷テストで検証
5. **デプロイと監視**: 変更をデプロイし、効果を継続的に監視

## 継続的最適化のためのベストプラクティス

1. **定期的なパフォーマンスレビュー**: 毎週のパフォーマンスレビュー会議
2. **最適化の優先順位付け**: ユーザー体験に最も影響する問題を優先
3. **データ駆動型の決定**: モニタリングデータに基づく最適化決定
4. **段階的な変更**: リスクを最小限に抑えるための段階的な変更
5. **A/Bテスト**: 重要な最適化のためのA/Bテスト

## 今後の課題

1. **より粒度の細かいモニタリング**: コンポーネントレベルのパフォーマンス指標
2. **予測分析**: 機械学習を使用したパフォーマンス問題の予測
3. **自動スケーリング**: 負荷に基づく自動リソース調整
4. **エンドツーエンドモニタリング**: クライアントからデータベースまでの全体的な応答時間の追跡